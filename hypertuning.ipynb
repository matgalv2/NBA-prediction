{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-04T21:08:52.202768Z",
     "start_time": "2024-06-04T21:08:47.747722Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T21:08:54.371774Z",
     "start_time": "2024-06-04T21:08:54.277649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw_dataset = pd.read_csv('resources/datasets/data.csv', sep='\\t')\n",
    "\n",
    "raw_dataset.head()"
   ],
   "id": "14a1da557637b091",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    GAME_ID      MATCHUP  OUTCOME  TEAM_ID_home TEAM_ABBREVIATION_home  \\\n",
       "0  22300848  LAC vs. LAL        0    1610612746                    LAC   \n",
       "1  22300995  MIN vs. DEN        0    1610612750                    MIN   \n",
       "2  22300928  ORL vs. IND        0    1610612753                    ORL   \n",
       "3  22301112  NYK vs. SAC        1    1610612752                    NYK   \n",
       "4  22300786  DEN vs. SAC        0    1610612743                    DEN   \n",
       "\n",
       "   FG_PCT_home  FG3_PCT_home  FT_PCT_home  REB_home  OREB_home  ...  \\\n",
       "0        0.506         0.270        0.750        36          9  ...   \n",
       "1        0.477         0.343        0.696        37          8  ...   \n",
       "2        0.375         0.250        0.759        46         13  ...   \n",
       "3        0.550         0.429        0.690        39          9  ...   \n",
       "4        0.393         0.346        0.864        45         12  ...   \n",
       "\n",
       "   DREB_away  AST_away  STL_away  BLK_away  OFF_RATING_away  DEF_RATING_away  \\\n",
       "0         31        28         6         5            117.2            114.3   \n",
       "1         38        26         5         1            118.6            114.3   \n",
       "2         41        20         5        10            112.1             98.0   \n",
       "3         26        26         6         3            114.7            127.7   \n",
       "4         38        21         7         5            100.0             97.0   \n",
       "\n",
       "   TS_PCT_away  TOV_away  ELO_away  SENTIMENT_away  \n",
       "0        0.642        15    1465.0        0.000000  \n",
       "1        0.634        17    1618.0        0.000000  \n",
       "2        0.600        12    1477.0        0.408076  \n",
       "3        0.597        16    1515.0        0.536685  \n",
       "4        0.524        14    1488.0        0.411101  \n",
       "\n",
       "[5 rows x 37 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>MATCHUP</th>\n",
       "      <th>OUTCOME</th>\n",
       "      <th>TEAM_ID_home</th>\n",
       "      <th>TEAM_ABBREVIATION_home</th>\n",
       "      <th>FG_PCT_home</th>\n",
       "      <th>FG3_PCT_home</th>\n",
       "      <th>FT_PCT_home</th>\n",
       "      <th>REB_home</th>\n",
       "      <th>OREB_home</th>\n",
       "      <th>...</th>\n",
       "      <th>DREB_away</th>\n",
       "      <th>AST_away</th>\n",
       "      <th>STL_away</th>\n",
       "      <th>BLK_away</th>\n",
       "      <th>OFF_RATING_away</th>\n",
       "      <th>DEF_RATING_away</th>\n",
       "      <th>TS_PCT_away</th>\n",
       "      <th>TOV_away</th>\n",
       "      <th>ELO_away</th>\n",
       "      <th>SENTIMENT_away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22300848</td>\n",
       "      <td>LAC vs. LAL</td>\n",
       "      <td>0</td>\n",
       "      <td>1610612746</td>\n",
       "      <td>LAC</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.750</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>117.2</td>\n",
       "      <td>114.3</td>\n",
       "      <td>0.642</td>\n",
       "      <td>15</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22300995</td>\n",
       "      <td>MIN vs. DEN</td>\n",
       "      <td>0</td>\n",
       "      <td>1610612750</td>\n",
       "      <td>MIN</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.696</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>118.6</td>\n",
       "      <td>114.3</td>\n",
       "      <td>0.634</td>\n",
       "      <td>17</td>\n",
       "      <td>1618.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22300928</td>\n",
       "      <td>ORL vs. IND</td>\n",
       "      <td>0</td>\n",
       "      <td>1610612753</td>\n",
       "      <td>ORL</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.759</td>\n",
       "      <td>46</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>112.1</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>12</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>0.408076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22301112</td>\n",
       "      <td>NYK vs. SAC</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612752</td>\n",
       "      <td>NYK</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.690</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>114.7</td>\n",
       "      <td>127.7</td>\n",
       "      <td>0.597</td>\n",
       "      <td>16</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>0.536685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22300786</td>\n",
       "      <td>DEN vs. SAC</td>\n",
       "      <td>0</td>\n",
       "      <td>1610612743</td>\n",
       "      <td>DEN</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.864</td>\n",
       "      <td>45</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>14</td>\n",
       "      <td>1488.0</td>\n",
       "      <td>0.411101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T21:08:56.734324Z",
     "start_time": "2024-06-04T21:08:56.718558Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = raw_dataset.drop(columns=['GAME_ID', 'MATCHUP', 'TEAM_ID_home', 'TEAM_ABBREVIATION_home','TEAM_ID_away', 'TEAM_ABBREVIATION_away'])",
   "id": "f7882de63513c69b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "attributes_to_be_normalized = [\n",
    "    'FG_PCT_home',\n",
    "    'FG3_PCT_home', 'FT_PCT_home', 'REB_home', 'OREB_home', 'DREB_home', 'AST_home','STL_home',\n",
    "    'BLK_home', 'OFF_RATING_home', 'DEF_RATING_home', 'TS_PCT_home', 'TOV_home', 'ELO_home',\n",
    "    \"SENTIMENT_home\", 'FG_PCT_away', 'FG3_PCT_away',\n",
    "    'FT_PCT_away', 'REB_away', 'OREB_away', 'DREB_away', 'AST_away', 'STL_away', 'BLK_away',\n",
    "    'OFF_RATING_away', 'DEF_RATING_away', 'TS_PCT_away', 'TOV_away', 'ELO_away', \"SENTIMENT_away\"\n",
    "]\n",
    "\n",
    "dataset[attributes_to_be_normalized] = StandardScaler().fit_transform(dataset[attributes_to_be_normalized])\n"
   ],
   "id": "1b422539f1afafd0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T21:08:57.771777Z",
     "start_time": "2024-06-04T21:08:57.757451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = dataset.sample(frac=0.9, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ],
   "id": "7fae5f3accdc149e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T21:08:58.615876Z",
     "start_time": "2024-06-04T21:08:58.600228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop('OUTCOME')\n",
    "test_labels = test_features.pop('OUTCOME')"
   ],
   "id": "2b4b9822ca05eb3c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Models",
   "id": "6f99ca3395f5dadd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T21:09:03.884480Z",
     "start_time": "2024-06-04T21:09:03.867572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models = {\n",
    "    \"mlp\": MLPClassifier(max_iter=10000),\n",
    "    \"svm\": svm.SVC(),\n",
    "    \"lgr\": LogisticRegression(),\n",
    "    \"rf\": RandomForestClassifier(),\n",
    "    \"gnb\": GaussianNB(),\n",
    "}"
   ],
   "id": "bc5c35c5b839720e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hyper tuning ",
   "id": "9cf87628e81f79ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T21:09:08.630674Z",
     "start_time": "2024-06-04T21:09:08.616703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hypertune(x, y, model, grid):\n",
    "    cv = KFold(n_splits=10)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy', error_score=0, verbose=2)\n",
    "    grid_result = grid_search.fit(x, y)\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    return zip(means, params)"
   ],
   "id": "f4fb9ebf14593997",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## MLP parameters",
   "id": "7b4e5100eb2ca4c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T21:09:17.890207Z",
     "start_time": "2024-06-04T21:09:17.876823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hiddenLayer_generator():\n",
    "    result = []\n",
    "    for i in range(1,5):\n",
    "        for no_layers in range(1,11):\n",
    "            layers = []\n",
    "            for _ in range(no_layers):\n",
    "                layers.append((len(train_dataset.columns) + 1)/2 *  2 * i )\n",
    "            result.append(layers)\n",
    "    return result"
   ],
   "id": "e85b878f84055c0a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T21:11:14.348030Z",
     "start_time": "2024-06-04T21:11:14.337456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "activation = ['logistic', 'tanh', 'relu']\n",
    "solver = ['sgd', 'adam']\n",
    "\n",
    "alpha = [10**i for i in range(-5,0)]\n",
    "learning_rate_init = [1e-1, 1e-2, 1e-3, 1e-4]\n",
    "learning_rate = ['adaptive', 'invscaling']\n",
    "\n",
    "# hidden_layer_sizes = hiddenLayer_generator()\n",
    "hidden_layer_sizes = range(128, 513)\n",
    "mlp_grid = dict(\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    activation=activation,\n",
    "    solver=solver,\n",
    "    alpha=alpha,\n",
    "    learning_rate=learning_rate,\n",
    "    learning_rate_init = learning_rate_init\n",
    ")"
   ],
   "id": "207a67bf208af751",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-04T21:12:30.795672Z",
     "start_time": "2024-06-04T21:11:40.297899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('resources/models/hyper-tuning/neural-network.tsv', 'a') as file:\n",
    "    file.write(f'hidden_layer_sizes\\tactivation\\tsolver\\talpha\\tlearning_rate\\tlearning_rate_init\\taccuracy\\n')\n",
    "    combinations = hypertune(train_features, train_labels, models[\"mlp\"], mlp_grid)\n",
    "    for mean, param in combinations:\n",
    "        hidden_layer_sizes = param['hidden_layer_sizes']\n",
    "        activation = param[\"activation\"]\n",
    "        solver = param[\"solver\"]\n",
    "        alpha = param[\"alpha\"]\n",
    "        learning_rate = param[\"learning_rate\"]\n",
    "        learning_rate_init = param[\"learning_rate_init\"]\n",
    "\n",
    "        file.write(f\"{hidden_layer_sizes}\\t{activation}\\t{solver}\\t{alpha}\\t{learning_rate}\\t{learning_rate_init}\\t{round(mean,5)}\\n\")"
   ],
   "id": "895fadbe3632fb52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 92400 candidates, totalling 924000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## SVM parameters",
   "id": "22f4e5ab0bacecb6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T16:58:03.901189Z",
     "start_time": "2024-06-03T16:58:03.885556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "C = [1000, 100, 50, 10, 1.0, 0.1, 0.01]\n",
    "degree = range(1,20)\n",
    "probability=[True, False]\n",
    "svm_grid = dict(kernel=kernel,C=C,degree=degree, probability=probability)"
   ],
   "id": "49faf0c3a18fce44",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T16:58:12.871210Z",
     "start_time": "2024-06-03T16:58:05.201172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('resources/models/hyper-tuning/svm.tsv', 'w') as file:\n",
    "    file.write(f'C\\tkernel\\tdegree\\tprobability\\taccuracy\\n')\n",
    "    combinations = hypertune(train_features, train_labels, models[\"svm\"], svm_grid)\n",
    "    for mean, param in combinations:\n",
    "        c,degree, kernel = param[\"C\"], param[\"degree\"], param[\"kernel\"], param[\"probability\"]\n",
    "        if kernel != \"poly\":\n",
    "            degree = \"-\"\n",
    "        file.write(f\"{c}\\t{kernel}\\t{degree}\\t{probability}\\t{round(mean,5)}\\n\")"
   ],
   "id": "1b968fe54e5ab213",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1064 candidates, totalling 10640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Logistic regression parameters",
   "id": "a76ac6a34106d493"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T08:18:03.888149Z",
     "start_time": "2024-06-01T08:18:03.872493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "penalty1 = ['l1']\n",
    "solvers1 = ['saga', 'liblinear']\n",
    "c_values1 = [100, 10, 1.0, 0.1, 0.01]\n",
    "lgr_grid1 = dict(solver=solvers1, penalty=penalty1, C=c_values1)\n",
    "\n",
    "penalty2 = ['l2']\n",
    "solvers2 = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "c_values2 = [100, 10, 1.0, 0.1, 0.01]\n",
    "lgr_grid2 = dict(solver=solvers2, penalty=penalty2, C=c_values2)"
   ],
   "id": "ee08bd4e61156b60",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T08:19:54.356714Z",
     "start_time": "2024-06-01T08:19:52.175020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('resources/models/hyper-tuning/logistic-regression.tsv', 'x') as file:\n",
    "    file.write(f'C\\tregularization\\tsolver\\taccuracy\\n')\n",
    "    combinations1 = hypertune(train_features, train_labels, models[\"lgr\"], lgr_grid1)\n",
    "    for mean, param in combinations1:\n",
    "        c, penalty ,solver = param[\"C\"], param[\"penalty\"], param[\"solver\"]\n",
    "        file.write(f\"{c}\\t{penalty}\\t{solver}\\t{round(mean,5)}\\n\")\n",
    "        \n",
    "    combinations2 = hypertune(train_features, train_labels, models[\"lgr\"], lgr_grid2)\n",
    "    for mean, param in combinations2:\n",
    "        c, penalty ,solver = param[\"C\"], param[\"penalty\"], param[\"solver\"]\n",
    "        file.write(f\"{c}\\t{penalty}\\t{solver}\\t{round(mean,5)}\\n\")"
   ],
   "id": "992b90c5860cf9e7",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Random forest parameters",
   "id": "8fbc6d3ef48cc549"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T15:35:56.989414Z",
     "start_time": "2024-06-01T15:35:56.958226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_estimators = range(1,101)\n",
    "max_features = range(1, 31)\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)] + [None]\n",
    "min_samples_split = range(1,11)\n",
    "min_samples_leaf = range(1,5)\n",
    "bootstrap = [True, False]\n",
    "\n",
    "\n",
    "rf_grid = dict(n_estimators=n_estimators, max_features=max_features, max_depth=max_depth, min_samples_split=min_samples_split, bootstrap=bootstrap)"
   ],
   "id": "a02d81438cb7ca1c",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m n_estimators \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m101\u001B[39m)\n\u001B[0;32m      2\u001B[0m max_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m31\u001B[39m)\n\u001B[1;32m----> 4\u001B[0m max_depth \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mint\u001B[39m(x) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241m.\u001B[39mlinspace(\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m110\u001B[39m, num \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m11\u001B[39m)] \u001B[38;5;241m+\u001B[39m [\u001B[38;5;28;01mNone\u001B[39;00m]\n\u001B[0;32m      5\u001B[0m min_samples_split \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m11\u001B[39m)\n\u001B[0;32m      6\u001B[0m min_samples_leaf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m5\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'np' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-01T10:50:55.886452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('resources/models/hyper-tuning/random-forest.tsv', 'x') as file:\n",
    "    file.write(f'n_estimators\\tmax_features\\tmax_depth\\tmin_samples_split\\tmin_samples_leaf\\tbagging\\taccuracy\\n')\n",
    "    combinations = hypertune(train_features, train_labels, models[\"rf\"], rf_grid)\n",
    "    for mean, param in combinations:\n",
    "        n_estimators = param[\"n_estimators\"]\n",
    "        max_features = param[\"max_features\"]\n",
    "        max_depth = param[\"max_depth\"]\n",
    "        min_samples_split = param[\"min_samples_split\"]\n",
    "        min_samples_leaf = param[\"min_samples_leaf\"]\n",
    "        bootstrap = param[\"bootstrap\"]\n",
    "        \n",
    "        file.write(f\"{n_estimators}\\t{max_features}\\t{max_depth}\\t{min_samples_split}\\t{min_samples_leaf}\\t{bootstrap}\\t{round(mean,5)}\\n\")"
   ],
   "id": "846a576c90fba5fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Naive Bayes parameters",
   "id": "a68c838972b6bfc6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T10:44:11.537409Z",
     "start_time": "2024-06-01T10:44:11.506130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "var_smoothing = [10**i for i in range(-11, -7)]\n",
    "gnb_grid = dict(var_smoothing=var_smoothing)"
   ],
   "id": "cf8ab8e2eadcbfb1",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T10:44:16.522914Z",
     "start_time": "2024-06-01T10:44:12.645757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('resources/models/hyper-tuning/gaussian-naive-bayes.tsv', 'x') as file:\n",
    "    file.write(f'var_smoothing\\taccuracy\\n')\n",
    "    combinations = hypertune(train_features, train_labels, models[\"gnb\"], gnb_grid)\n",
    "    for mean, param in combinations:\n",
    "        var_smoothing = param[\"var_smoothing\"]\n",
    "        file.write(f\"{var_smoothing}\\t{round(mean,5)}\\n\")"
   ],
   "id": "ef0a58e37df96f47",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
