{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-01T08:11:46.536916Z",
     "start_time": "2024-06-01T08:11:43.896631Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from typing import TextIO\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T08:11:46.583791Z",
     "start_time": "2024-06-01T08:11:46.536916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw_dataset = pd.read_csv('resources/datasets/data.csv', sep='\\t')\n",
    "\n",
    "raw_dataset.head()"
   ],
   "id": "14a1da557637b091",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    GAME_ID      MATCHUP  OUTCOME  TEAM_ID_home TEAM_ABBREVIATION_home  \\\n",
       "0  22300848  LAC vs. LAL        0    1610612746                    LAC   \n",
       "1  22300995  MIN vs. DEN        0    1610612750                    MIN   \n",
       "2  22300928  ORL vs. IND        0    1610612753                    ORL   \n",
       "3  22301112  NYK vs. SAC        1    1610612752                    NYK   \n",
       "4  22300786  DEN vs. SAC        0    1610612743                    DEN   \n",
       "\n",
       "   FG_PCT_home  FG3_PCT_home  FT_PCT_home  REB_home  OREB_home  ...  \\\n",
       "0     0.535503      0.354497     0.625187  0.224490       0.36  ...   \n",
       "1     0.449704      0.483245     0.544228  0.244898       0.32  ...   \n",
       "2     0.147929      0.319224     0.638681  0.428571       0.52  ...   \n",
       "3     0.665680      0.634921     0.535232  0.285714       0.36  ...   \n",
       "4     0.201183      0.488536     0.796102  0.408163       0.48  ...   \n",
       "\n",
       "   DREB_away  AST_away  STL_away  BLK_away  OFF_RATING_away  DEF_RATING_away  \\\n",
       "0   0.371429  0.592593    0.3125  0.333333         0.502571         0.532857   \n",
       "1   0.571429  0.518519    0.2500  0.066667         0.520566         0.532857   \n",
       "2   0.657143  0.296296    0.2500  0.666667         0.437018         0.300000   \n",
       "3   0.228571  0.518519    0.3125  0.200000         0.470437         0.724286   \n",
       "4   0.571429  0.333333    0.3750  0.333333         0.281491         0.285714   \n",
       "\n",
       "   TS_PCT_away  TOV_away  ELO_away  SENTIMENT_away  \n",
       "0     0.698895      0.60  0.510972        0.000000  \n",
       "1     0.676796      0.70  0.750784        0.000000  \n",
       "2     0.582873      0.45  0.529781        0.432975  \n",
       "3     0.574586      0.65  0.589342        0.569431  \n",
       "4     0.372928      0.55  0.547022        0.436185  \n",
       "\n",
       "[5 rows x 37 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>MATCHUP</th>\n",
       "      <th>OUTCOME</th>\n",
       "      <th>TEAM_ID_home</th>\n",
       "      <th>TEAM_ABBREVIATION_home</th>\n",
       "      <th>FG_PCT_home</th>\n",
       "      <th>FG3_PCT_home</th>\n",
       "      <th>FT_PCT_home</th>\n",
       "      <th>REB_home</th>\n",
       "      <th>OREB_home</th>\n",
       "      <th>...</th>\n",
       "      <th>DREB_away</th>\n",
       "      <th>AST_away</th>\n",
       "      <th>STL_away</th>\n",
       "      <th>BLK_away</th>\n",
       "      <th>OFF_RATING_away</th>\n",
       "      <th>DEF_RATING_away</th>\n",
       "      <th>TS_PCT_away</th>\n",
       "      <th>TOV_away</th>\n",
       "      <th>ELO_away</th>\n",
       "      <th>SENTIMENT_away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22300848</td>\n",
       "      <td>LAC vs. LAL</td>\n",
       "      <td>0</td>\n",
       "      <td>1610612746</td>\n",
       "      <td>LAC</td>\n",
       "      <td>0.535503</td>\n",
       "      <td>0.354497</td>\n",
       "      <td>0.625187</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.502571</td>\n",
       "      <td>0.532857</td>\n",
       "      <td>0.698895</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.510972</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22300995</td>\n",
       "      <td>MIN vs. DEN</td>\n",
       "      <td>0</td>\n",
       "      <td>1610612750</td>\n",
       "      <td>MIN</td>\n",
       "      <td>0.449704</td>\n",
       "      <td>0.483245</td>\n",
       "      <td>0.544228</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.520566</td>\n",
       "      <td>0.532857</td>\n",
       "      <td>0.676796</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.750784</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22300928</td>\n",
       "      <td>ORL vs. IND</td>\n",
       "      <td>0</td>\n",
       "      <td>1610612753</td>\n",
       "      <td>ORL</td>\n",
       "      <td>0.147929</td>\n",
       "      <td>0.319224</td>\n",
       "      <td>0.638681</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.52</td>\n",
       "      <td>...</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.437018</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.582873</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.529781</td>\n",
       "      <td>0.432975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22301112</td>\n",
       "      <td>NYK vs. SAC</td>\n",
       "      <td>1</td>\n",
       "      <td>1610612752</td>\n",
       "      <td>NYK</td>\n",
       "      <td>0.665680</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>0.535232</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.470437</td>\n",
       "      <td>0.724286</td>\n",
       "      <td>0.574586</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.589342</td>\n",
       "      <td>0.569431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22300786</td>\n",
       "      <td>DEN vs. SAC</td>\n",
       "      <td>0</td>\n",
       "      <td>1610612743</td>\n",
       "      <td>DEN</td>\n",
       "      <td>0.201183</td>\n",
       "      <td>0.488536</td>\n",
       "      <td>0.796102</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.281491</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.372928</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.547022</td>\n",
       "      <td>0.436185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T08:11:49.588428Z",
     "start_time": "2024-06-01T08:11:49.572804Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = raw_dataset.drop(columns=['GAME_ID', 'MATCHUP', 'TEAM_ID_home', 'TEAM_ABBREVIATION_home','TEAM_ID_away', 'TEAM_ABBREVIATION_away'])",
   "id": "f7882de63513c69b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T08:12:38.655405Z",
     "start_time": "2024-06-01T08:12:38.639757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = dataset.sample(frac=0.9, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ],
   "id": "7fae5f3accdc149e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T08:12:41.290574Z",
     "start_time": "2024-06-01T08:12:41.274904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop('OUTCOME')\n",
    "test_labels = test_features.pop('OUTCOME')"
   ],
   "id": "2b4b9822ca05eb3c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Models",
   "id": "6f99ca3395f5dadd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T08:12:45.262353Z",
     "start_time": "2024-06-01T08:12:45.246246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models = {\n",
    "    \"mlp\": MLPClassifier(max_iter=5000),\n",
    "    \"svm\": svm.SVC(),\n",
    "    \"lgr\": LogisticRegression(),\n",
    "    \"rf\": RandomForestClassifier(),\n",
    "    \"gnb\": GaussianNB(),\n",
    "}"
   ],
   "id": "bc5c35c5b839720e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## MLP parameters",
   "id": "7b4e5100eb2ca4c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T08:12:46.772001Z",
     "start_time": "2024-06-01T08:12:46.756324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hiddenLayer_generator():\n",
    "    result = []\n",
    "    for i in range(1,5):\n",
    "        for no_layers in range(1,21):\n",
    "            layers = []\n",
    "            for _ in range(no_layers):\n",
    "                layers.append((len(train_dataset.columns) + 1)/2 *  2 * i )\n",
    "            result.append(layers)\n",
    "    return result"
   ],
   "id": "e85b878f84055c0a",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T08:12:49.091722Z",
     "start_time": "2024-06-01T08:12:49.076031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hypertune_mlp(x, y, model, grid, file: TextIO):\n",
    "    cv = KFold(n_splits=10)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy', error_score=0, verbose=1)\n",
    "    grid_result = grid_search.fit(x, y)\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, param in zip(means, params):\n",
    "        # hidden_layer_sizes = f\"{param['hidden_layer_sizes'][0]} x {len(param['hidden_layer_sizes'])}\"\n",
    "        hidden_layer_sizes = param['hidden_layer_sizes']\n",
    "        activation = param[\"activation\"]\n",
    "        solver = param[\"solver\"]\n",
    "        alpha = param[\"alpha\"]\n",
    "        learning_rate = param[\"learning_rate\"]\n",
    "        learning_rate_init = param[\"learning_rate_init\"]\n",
    "\n",
    "        file.write(f\"{hidden_layer_sizes}\\t{activation}\\t{solver}\\t{alpha}\\t{learning_rate}\\t{learning_rate_init}\\t{round(mean,5)}\\n\")"
   ],
   "id": "ffcea7b79a3987cb",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T08:12:51.459224Z",
     "start_time": "2024-06-01T08:12:51.443617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "activation = ['identity', 'logistic', 'tanh', 'relu']\n",
    "solver = ['lbfgs', 'sgd', 'adam']\n",
    "\n",
    "alpha = [10**i for i in range(-5,6)]\n",
    "learning_rate_init = [1e-1, 1e-2, 1e-3, 1e-4]\n",
    "learning_rate = ['constant', 'adaptive', 'invscaling']\n",
    "\n",
    "hidden_layer_sizes = hiddenLayer_generator()\n",
    "mlp_grid = dict(\n",
    "    hidden_layer_sizes=hidden_layer_sizes,\n",
    "    activation=activation,\n",
    "    solver=solver,\n",
    "    alpha=alpha,\n",
    "    learning_rate=learning_rate,\n",
    "    learning_rate_init = learning_rate_init\n",
    ")"
   ],
   "id": "207a67bf208af751",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## SVM parameters",
   "id": "22f4e5ab0bacecb6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T08:16:35.438572Z",
     "start_time": "2024-06-01T08:16:35.422952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hypertune_svm(x, y, model, grid, file: TextIO):\n",
    "    cv = KFold(n_splits=10)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy', error_score=0)\n",
    "    grid_result = grid_search.fit(x, y)\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, param in zip(means, params):\n",
    "        c,degree, kernel = param[\"C\"], param[\"degree\"], param[\"kernel\"]\n",
    "        if kernel != \"poly\":\n",
    "            degree = \"-\"\n",
    "        file.write(f\"{c}\\t{kernel}\\t{degree}\\t{round(mean,5)}\\n\")"
   ],
   "id": "91a283974d96443",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T08:12:56.490531Z",
     "start_time": "2024-06-01T08:12:56.475474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "C = [1000, 100, 50, 10, 1.0, 0.1, 0.01]\n",
    "degree = range(1,20)\n",
    "svm_grid = dict(kernel=kernel,C=C,degree=degree)"
   ],
   "id": "49faf0c3a18fce44",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T08:17:11.213658Z",
     "start_time": "2024-06-01T08:16:53.872075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('resources/models/hyper-tuning/svm.tsv', 'x') as file:\n",
    "    file.write(f'C\\tkernel\\tdegree\\taccuracy\\n')\n",
    "    hypertune_svm(train_features, train_labels, models[\"svm\"], svm_grid, file)"
   ],
   "id": "1b968fe54e5ab213",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Logistic regression parameters",
   "id": "a76ac6a34106d493"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T08:19:47.408709Z",
     "start_time": "2024-06-01T08:19:47.388560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hypertune_lgr(x, y, model, grid, file: TextIO):\n",
    "    cv = KFold(n_splits=10)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy', error_score=0)\n",
    "    grid_result = grid_search.fit(x, y)\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, param in zip(means, params):\n",
    "        c, penalty ,solver = param[\"C\"], param[\"penalty\"], param[\"solver\"]\n",
    "        file.write(f\"{c}\\t{penalty}\\t{solver}\\t{round(mean,5)}\\n\")"
   ],
   "id": "c2d1d07b3ae8cdc9",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T08:18:03.888149Z",
     "start_time": "2024-06-01T08:18:03.872493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "penalty1 = ['l1']\n",
    "solvers1 = ['saga', 'liblinear']\n",
    "c_values1 = [100, 10, 1.0, 0.1, 0.01]\n",
    "lgr_grid1 = dict(solver=solvers1, penalty=penalty1, C=c_values1)\n",
    "\n",
    "penalty2 = ['l2']\n",
    "solvers2 = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "c_values2 = [100, 10, 1.0, 0.1, 0.01]\n",
    "lgr_grid2 = dict(solver=solvers2, penalty=penalty2, C=c_values2)"
   ],
   "id": "ee08bd4e61156b60",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T08:19:54.356714Z",
     "start_time": "2024-06-01T08:19:52.175020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('resources/models/hyper-tuning/lgr.tsv', 'x') as file:\n",
    "    file.write(f'C\\tregularization\\tsolver\\taccuracy\\n')\n",
    "    hypertune_lgr(train_features, train_labels, models[\"lgr\"], lgr_grid1, file)\n",
    "    hypertune_lgr(train_features, train_labels, models[\"lgr\"], lgr_grid2, file)"
   ],
   "id": "992b90c5860cf9e7",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Random forest parameters",
   "id": "8fbc6d3ef48cc549"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T08:21:33.710009Z",
     "start_time": "2024-06-01T08:21:33.694332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hypertune_rf(x, y, model, grid, file: TextIO):\n",
    "    cv = KFold(n_splits=10)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy', error_score=0)\n",
    "    grid_result = grid_search.fit(x, y)\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, param in zip(means, params):\n",
    "        n_estimators, max_features = param[\"n_estimators\"], param[\"max_features\"]\n",
    "        file.write(f\"{n_estimators}\\t{max_features}\\t{round(mean,5)}\\n\")"
   ],
   "id": "915c7c37e656e5cd",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T08:21:34.806159Z",
     "start_time": "2024-06-01T08:21:34.790482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_estimators = range(1,101)\n",
    "max_features = range(1, 31)\n",
    "                     \n",
    "rf_grid = dict(n_estimators=n_estimators, max_features=max_features)"
   ],
   "id": "a02d81438cb7ca1c",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-01T08:21:36.393164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('resources/models/hyper-tuning/rf.tsv', 'x') as file:\n",
    "    file.write(f'n_estimators\\tmax_features\\taccuracy\\n')\n",
    "    hypertune_lgr(train_features, train_labels, models[\"rf\"], rf_grid, file)"
   ],
   "id": "846a576c90fba5fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Naive Bayes parameters",
   "id": "a68c838972b6bfc6"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "def hypertune_gnb(x, y, model, grid, file: TextIO):\n",
    "    cv = KFold(n_splits=10)\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy', error_score=0)\n",
    "    grid_result = grid_search.fit(x, y)\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, param in zip(means, params):\n",
    "        var_smoothing = param[\"var_smoothing\"]\n",
    "        file.write(f\"{var_smoothing}\\t{round(mean,5)}\\n\")"
   ],
   "id": "9a4c715d5704be71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "var_smoothing = [10**i for i in range(-11, -7)]\n",
    "\n",
    "gnb_grid = dict(var_smoothing=var_smoothing)"
   ],
   "id": "cf8ab8e2eadcbfb1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "with open('resources/models/hyper-tuning/gnb.tsv', 'x') as file:\n",
    "    file.write(f'var_smoothing\\taccuracy\\n')\n",
    "    hypertune_lgr(train_features, train_labels, models[\"gnb\"], gnb_grid, file)"
   ],
   "id": "ef0a58e37df96f47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "===================================================",
   "id": "dc192c252bd1618"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3b73c741aafdc282"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T21:42:38.585872Z",
     "start_time": "2024-05-31T21:42:38.522917Z"
    }
   },
   "cell_type": "code",
   "source": "train_features.describe()",
   "id": "7469e88bb3d36643",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       FG_PCT_home  FG3_PCT_home  FT_PCT_home    REB_home   OREB_home  \\\n",
       "count   436.000000    436.000000   436.000000  436.000000  436.000000   \n",
       "mean      0.448232      0.518559     0.686220    0.386210    0.419266   \n",
       "std       0.164460      0.143584     0.157707    0.136977    0.147673   \n",
       "min       0.000000      0.000000     0.000000    0.000000    0.000000   \n",
       "25%       0.343195      0.425044     0.585457    0.285714    0.320000   \n",
       "50%       0.446746      0.521164     0.700150    0.387755    0.400000   \n",
       "75%       0.565089      0.607143     0.800600    0.474490    0.520000   \n",
       "max       1.000000      1.000000     1.000000    1.000000    1.000000   \n",
       "\n",
       "        DREB_home    AST_home    STL_home    BLK_home  OFF_RATING_home  \\\n",
       "count  436.000000  436.000000  436.000000  436.000000       436.000000   \n",
       "mean     0.432702    0.452784    0.416714    0.322821         0.532267   \n",
       "std      0.145422    0.172909    0.172112    0.171258         0.161469   \n",
       "min      0.000000    0.000000    0.000000    0.000000         0.000000   \n",
       "25%      0.342105    0.344828    0.312500    0.187500         0.424286   \n",
       "50%      0.421053    0.448276    0.375000    0.312500         0.530000   \n",
       "75%      0.526316    0.551724    0.500000    0.437500         0.637143   \n",
       "max      1.000000    1.000000    1.000000    1.000000         1.000000   \n",
       "\n",
       "       DEF_RATING_home  TS_PCT_home    TOV_home    ELO_home  SENTIMENT_home  \\\n",
       "count       436.000000   436.000000  436.000000  436.000000      436.000000   \n",
       "mean          0.445452     0.479173    0.390307    0.488478        0.411210   \n",
       "std           0.158150     0.157384    0.165117    0.231713        0.221155   \n",
       "min           0.000000     0.000000    0.000000    0.000000        0.000000   \n",
       "25%           0.338689     0.372796    0.260870    0.348653        0.341192   \n",
       "50%           0.460154     0.478589    0.391304    0.536450        0.463029   \n",
       "75%           0.551735     0.591940    0.478261    0.648177        0.560592   \n",
       "max           1.000000     1.000000    0.913043    1.000000        0.987073   \n",
       "\n",
       "       FG_PCT_away  FG3_PCT_away  FT_PCT_away    REB_away   OREB_away  \\\n",
       "count   436.000000    436.000000   436.000000  436.000000  436.000000   \n",
       "mean      0.519696      0.460158     0.772956    0.439093    0.387833   \n",
       "std       0.187437      0.167892     0.115250    0.177679    0.178699   \n",
       "min       0.000000      0.000000     0.000000    0.000000    0.000000   \n",
       "25%       0.395134      0.345309     0.714000    0.333333    0.238095   \n",
       "50%       0.533557      0.455090     0.789000    0.416667    0.380952   \n",
       "75%       0.657718      0.562874     0.846000    0.555556    0.476190   \n",
       "max       1.000000      1.000000     1.000000    1.000000    1.000000   \n",
       "\n",
       "        DREB_away    AST_away    STL_away    BLK_away  OFF_RATING_away  \\\n",
       "count  436.000000  436.000000  436.000000  436.000000       436.000000   \n",
       "mean     0.418938    0.527778    0.414994    0.334251         0.445452   \n",
       "std      0.151008    0.189833    0.179010    0.173608         0.158150   \n",
       "min      0.028571    0.000000    0.000000    0.000000         0.000000   \n",
       "25%      0.314286    0.407407    0.312500    0.200000         0.338689   \n",
       "50%      0.400000    0.518519    0.437500    0.333333         0.460154   \n",
       "75%      0.514286    0.629630    0.500000    0.466667         0.551735   \n",
       "max      1.000000    1.000000    0.937500    1.000000         1.000000   \n",
       "\n",
       "       DEF_RATING_away  TS_PCT_away    TOV_away    ELO_away  SENTIMENT_away  \n",
       "count       436.000000   436.000000  436.000000  436.000000      436.000000  \n",
       "mean          0.532267     0.513362    0.490023    0.491764        0.440125  \n",
       "std           0.161469     0.174807    0.175408    0.231488        0.227778  \n",
       "min           0.000000     0.000000    0.000000    0.000000        0.000000  \n",
       "25%           0.424286     0.392265    0.350000    0.357759        0.395137  \n",
       "50%           0.530000     0.516575    0.500000    0.547806        0.493502  \n",
       "75%           0.637143     0.629834    0.600000    0.660266        0.592908  \n",
       "max           1.000000     1.000000    1.000000    1.000000        1.000000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FG_PCT_home</th>\n",
       "      <th>FG3_PCT_home</th>\n",
       "      <th>FT_PCT_home</th>\n",
       "      <th>REB_home</th>\n",
       "      <th>OREB_home</th>\n",
       "      <th>DREB_home</th>\n",
       "      <th>AST_home</th>\n",
       "      <th>STL_home</th>\n",
       "      <th>BLK_home</th>\n",
       "      <th>OFF_RATING_home</th>\n",
       "      <th>DEF_RATING_home</th>\n",
       "      <th>TS_PCT_home</th>\n",
       "      <th>TOV_home</th>\n",
       "      <th>ELO_home</th>\n",
       "      <th>SENTIMENT_home</th>\n",
       "      <th>FG_PCT_away</th>\n",
       "      <th>FG3_PCT_away</th>\n",
       "      <th>FT_PCT_away</th>\n",
       "      <th>REB_away</th>\n",
       "      <th>OREB_away</th>\n",
       "      <th>DREB_away</th>\n",
       "      <th>AST_away</th>\n",
       "      <th>STL_away</th>\n",
       "      <th>BLK_away</th>\n",
       "      <th>OFF_RATING_away</th>\n",
       "      <th>DEF_RATING_away</th>\n",
       "      <th>TS_PCT_away</th>\n",
       "      <th>TOV_away</th>\n",
       "      <th>ELO_away</th>\n",
       "      <th>SENTIMENT_away</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>436.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.448232</td>\n",
       "      <td>0.518559</td>\n",
       "      <td>0.686220</td>\n",
       "      <td>0.386210</td>\n",
       "      <td>0.419266</td>\n",
       "      <td>0.432702</td>\n",
       "      <td>0.452784</td>\n",
       "      <td>0.416714</td>\n",
       "      <td>0.322821</td>\n",
       "      <td>0.532267</td>\n",
       "      <td>0.445452</td>\n",
       "      <td>0.479173</td>\n",
       "      <td>0.390307</td>\n",
       "      <td>0.488478</td>\n",
       "      <td>0.411210</td>\n",
       "      <td>0.519696</td>\n",
       "      <td>0.460158</td>\n",
       "      <td>0.772956</td>\n",
       "      <td>0.439093</td>\n",
       "      <td>0.387833</td>\n",
       "      <td>0.418938</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.414994</td>\n",
       "      <td>0.334251</td>\n",
       "      <td>0.445452</td>\n",
       "      <td>0.532267</td>\n",
       "      <td>0.513362</td>\n",
       "      <td>0.490023</td>\n",
       "      <td>0.491764</td>\n",
       "      <td>0.440125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.164460</td>\n",
       "      <td>0.143584</td>\n",
       "      <td>0.157707</td>\n",
       "      <td>0.136977</td>\n",
       "      <td>0.147673</td>\n",
       "      <td>0.145422</td>\n",
       "      <td>0.172909</td>\n",
       "      <td>0.172112</td>\n",
       "      <td>0.171258</td>\n",
       "      <td>0.161469</td>\n",
       "      <td>0.158150</td>\n",
       "      <td>0.157384</td>\n",
       "      <td>0.165117</td>\n",
       "      <td>0.231713</td>\n",
       "      <td>0.221155</td>\n",
       "      <td>0.187437</td>\n",
       "      <td>0.167892</td>\n",
       "      <td>0.115250</td>\n",
       "      <td>0.177679</td>\n",
       "      <td>0.178699</td>\n",
       "      <td>0.151008</td>\n",
       "      <td>0.189833</td>\n",
       "      <td>0.179010</td>\n",
       "      <td>0.173608</td>\n",
       "      <td>0.158150</td>\n",
       "      <td>0.161469</td>\n",
       "      <td>0.174807</td>\n",
       "      <td>0.175408</td>\n",
       "      <td>0.231488</td>\n",
       "      <td>0.227778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.343195</td>\n",
       "      <td>0.425044</td>\n",
       "      <td>0.585457</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.424286</td>\n",
       "      <td>0.338689</td>\n",
       "      <td>0.372796</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.348653</td>\n",
       "      <td>0.341192</td>\n",
       "      <td>0.395134</td>\n",
       "      <td>0.345309</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.338689</td>\n",
       "      <td>0.424286</td>\n",
       "      <td>0.392265</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.357759</td>\n",
       "      <td>0.395137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.446746</td>\n",
       "      <td>0.521164</td>\n",
       "      <td>0.700150</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.460154</td>\n",
       "      <td>0.478589</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>0.536450</td>\n",
       "      <td>0.463029</td>\n",
       "      <td>0.533557</td>\n",
       "      <td>0.455090</td>\n",
       "      <td>0.789000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.460154</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.516575</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.547806</td>\n",
       "      <td>0.493502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.565089</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.800600</td>\n",
       "      <td>0.474490</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.637143</td>\n",
       "      <td>0.551735</td>\n",
       "      <td>0.591940</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.648177</td>\n",
       "      <td>0.560592</td>\n",
       "      <td>0.657718</td>\n",
       "      <td>0.562874</td>\n",
       "      <td>0.846000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.551735</td>\n",
       "      <td>0.637143</td>\n",
       "      <td>0.629834</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.660266</td>\n",
       "      <td>0.592908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T21:43:45.095908Z",
     "start_time": "2024-05-31T21:42:38.585872Z"
    }
   },
   "cell_type": "code",
   "source": "hypertune_mlp(train_features, train_labels, models[\"mlp\"], mlp_grid, None)",
   "id": "62c970532f3c3d84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 120384 candidates, totalling 1203840 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[1;32mx:\\programfiles\\jetbrains\\pycharmprojects\\nba-predictor\\venv\\lib\\site-packages\\joblib\\parallel.py:1595\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1594\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1595\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[0;32m   1597\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[0;32m   1598\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[0;32m   1599\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[0;32m   1600\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n",
      "File \u001B[1;32mx:\\programfiles\\jetbrains\\pycharmprojects\\nba-predictor\\venv\\lib\\site-packages\\joblib\\parallel.py:1707\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1704\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1705\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[0;32m   1706\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[1;32m-> 1707\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1708\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[75], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mhypertune_mlp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodels\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmlp\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmlp_grid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[68], line 4\u001B[0m, in \u001B[0;36mhypertune_mlp\u001B[1;34m(x, y, model, grid, file)\u001B[0m\n\u001B[0;32m      2\u001B[0m cv \u001B[38;5;241m=\u001B[39m KFold(n_splits\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n\u001B[0;32m      3\u001B[0m grid_search \u001B[38;5;241m=\u001B[39m GridSearchCV(estimator\u001B[38;5;241m=\u001B[39mmodel, param_grid\u001B[38;5;241m=\u001B[39mgrid, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, cv\u001B[38;5;241m=\u001B[39mcv, scoring\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m, error_score\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m----> 4\u001B[0m grid_result \u001B[38;5;241m=\u001B[39m \u001B[43mgrid_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m means \u001B[38;5;241m=\u001B[39m grid_result\u001B[38;5;241m.\u001B[39mcv_results_[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean_test_score\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      6\u001B[0m params \u001B[38;5;241m=\u001B[39m grid_result\u001B[38;5;241m.\u001B[39mcv_results_[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparams\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32mx:\\programfiles\\jetbrains\\pycharmprojects\\nba-predictor\\venv\\lib\\site-packages\\sklearn\\base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1471\u001B[0m     )\n\u001B[0;32m   1472\u001B[0m ):\n\u001B[1;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mx:\\programfiles\\jetbrains\\pycharmprojects\\nba-predictor\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:968\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, **params)\u001B[0m\n\u001B[0;32m    962\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    963\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    964\u001B[0m     )\n\u001B[0;32m    966\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 968\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    970\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    971\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    972\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32mx:\\programfiles\\jetbrains\\pycharmprojects\\nba-predictor\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1543\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1541\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1542\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1543\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mx:\\programfiles\\jetbrains\\pycharmprojects\\nba-predictor\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:914\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    906\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    907\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m    908\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    909\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    910\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[0;32m    911\u001B[0m         )\n\u001B[0;32m    912\u001B[0m     )\n\u001B[1;32m--> 914\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    915\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    916\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    917\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    918\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    919\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    920\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    921\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    922\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    923\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    924\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    925\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    926\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    927\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    928\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mrouted_params\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplitter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    929\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    930\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    932\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    933\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    934\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    935\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    936\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    937\u001B[0m     )\n",
      "File \u001B[1;32mx:\\programfiles\\jetbrains\\pycharmprojects\\nba-predictor\\venv\\lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     62\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     63\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     64\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     65\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     66\u001B[0m )\n\u001B[1;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mx:\\programfiles\\jetbrains\\pycharmprojects\\nba-predictor\\venv\\lib\\site-packages\\joblib\\parallel.py:1952\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1946\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[0;32m   1947\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[0;32m   1948\u001B[0m \u001B[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001B[39;00m\n\u001B[0;32m   1949\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[0;32m   1950\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 1952\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mx:\\programfiles\\jetbrains\\pycharmprojects\\nba-predictor\\venv\\lib\\site-packages\\joblib\\parallel.py:1648\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1646\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m:\n\u001B[0;32m   1647\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m-> 1648\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_abort\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1649\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m   1650\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m   1651\u001B[0m     \u001B[38;5;66;03m# Store the unconsumed tasks and terminate the workers if necessary\u001B[39;00m\n",
      "File \u001B[1;32mx:\\programfiles\\jetbrains\\pycharmprojects\\nba-predictor\\venv\\lib\\site-packages\\joblib\\parallel.py:1559\u001B[0m, in \u001B[0;36mParallel._abort\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1554\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_aborted \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mabort_everything\u001B[39m\u001B[38;5;124m'\u001B[39m)):\n\u001B[0;32m   1555\u001B[0m     \u001B[38;5;66;03m# If the backend is managed externally we need to make sure\u001B[39;00m\n\u001B[0;32m   1556\u001B[0m     \u001B[38;5;66;03m# to leave it in a working state to allow for future jobs\u001B[39;00m\n\u001B[0;32m   1557\u001B[0m     \u001B[38;5;66;03m# scheduling.\u001B[39;00m\n\u001B[0;32m   1558\u001B[0m     ensure_ready \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_managed_backend\n\u001B[1;32m-> 1559\u001B[0m     \u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mabort_everything\u001B[49m\u001B[43m(\u001B[49m\u001B[43mensure_ready\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_ready\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1560\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_aborted \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mx:\\programfiles\\jetbrains\\pycharmprojects\\nba-predictor\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py:632\u001B[0m, in \u001B[0;36mLokyBackend.abort_everything\u001B[1;34m(self, ensure_ready)\u001B[0m\n\u001B[0;32m    629\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mabort_everything\u001B[39m(\u001B[38;5;28mself\u001B[39m, ensure_ready\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m    630\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Shutdown the workers and restart a new one with the same parameters\u001B[39;00m\n\u001B[0;32m    631\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 632\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_workers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mterminate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkill_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    633\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    635\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ensure_ready:\n",
      "File \u001B[1;32mx:\\programfiles\\jetbrains\\pycharmprojects\\nba-predictor\\venv\\lib\\site-packages\\joblib\\executor.py:75\u001B[0m, in \u001B[0;36mMemmappingExecutor.terminate\u001B[1;34m(self, kill_workers)\u001B[0m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mterminate\u001B[39m(\u001B[38;5;28mself\u001B[39m, kill_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m---> 75\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshutdown\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkill_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkill_workers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     77\u001B[0m     \u001B[38;5;66;03m# When workers are killed in a brutal manner, they cannot execute the\u001B[39;00m\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;66;03m# finalizer of their shared memmaps. The refcount of those memmaps may\u001B[39;00m\n\u001B[0;32m     79\u001B[0m     \u001B[38;5;66;03m# be off by an unknown number, so instead of decref'ing them, we force\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;66;03m# with allow_non_empty=True but if we can't, it will be clean up later\u001B[39;00m\n\u001B[0;32m     85\u001B[0m     \u001B[38;5;66;03m# on by the resource_tracker.\u001B[39;00m\n\u001B[0;32m     86\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_submit_resize_lock:\n",
      "File \u001B[1;32mx:\\programfiles\\jetbrains\\pycharmprojects\\nba-predictor\\venv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:1303\u001B[0m, in \u001B[0;36mProcessPoolExecutor.shutdown\u001B[1;34m(self, wait, kill_workers)\u001B[0m\n\u001B[0;32m   1299\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m executor_manager_thread \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m wait:\n\u001B[0;32m   1300\u001B[0m     \u001B[38;5;66;03m# This locks avoids concurrent join if the interpreter\u001B[39;00m\n\u001B[0;32m   1301\u001B[0m     \u001B[38;5;66;03m# is shutting down.\u001B[39;00m\n\u001B[0;32m   1302\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m _global_shutdown_lock:\n\u001B[1;32m-> 1303\u001B[0m         \u001B[43mexecutor_manager_thread\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1304\u001B[0m         _threads_wakeups\u001B[38;5;241m.\u001B[39mpop(executor_manager_thread, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m   1306\u001B[0m \u001B[38;5;66;03m# To reduce the risk of opening too many files, remove references to\u001B[39;00m\n\u001B[0;32m   1307\u001B[0m \u001B[38;5;66;03m# objects that use file descriptors.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:1089\u001B[0m, in \u001B[0;36mThread.join\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m   1086\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot join current thread\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1088\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1089\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_wait_for_tstate_lock\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1090\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1091\u001B[0m     \u001B[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001B[39;00m\n\u001B[0;32m   1092\u001B[0m     \u001B[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001B[39;00m\n\u001B[0;32m   1093\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wait_for_tstate_lock(timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mmax\u001B[39m(timeout, \u001B[38;5;241m0\u001B[39m))\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:1105\u001B[0m, in \u001B[0;36mThread._wait_for_tstate_lock\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m   1103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m lock \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# already determined that the C code is done\u001B[39;00m\n\u001B[0;32m   1104\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_stopped\n\u001B[1;32m-> 1105\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[43mlock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1106\u001B[0m     lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m   1107\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stop()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 75
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
